import logging
import time

import numpy as np

# pylint: disable=import-error
from ...functional import scalar_square_add_gauss_with_max
from ... import visualizer

LOG = logging.getLogger(__name__)


class CifHr:
    neighbors = 16
    v_threshold = 0.1
    debug_visualizer = visualizer.CifHr()

    ablation_skip = False

    def __init__(self):
        self.accumulated = None

    def fill_single(self, all_fields, meta):
        return self.fill(all_fields, [meta])

    def accumulate(self, len_cifs, t, p, stride, min_scale):
        LOG.info(f'Original P: {p.shape}')
        p = p[:, p[0] > self.v_threshold]
        if min_scale:
            p = p[:, p[4] > min_scale / stride]

        LOG.info(f'Updated p: {p.shape}')

        # get the Confidence score, x, y, _, sigma that the x and y is the coordinates at the resolution of the input image after multiply with stride
        #  x and y are the offset vector coordinates => then use the [scalar_square_add_gauss_with_max] to generate the gaussian map of the hrcif this will be passed
        #  to seed in the pose decoder

        v, x, y, _, scale = p

        # LOG.info(f'Len-cifs: {len_cifs}, t = {t}, v = {v}, x = {x}, y = {y}, min_scale: {min_scale}, p = {p.shape}')

        x = x * stride
        y = y * stride
        sigma = np.maximum(1.0, 0.5 * scale * stride)

        # LOG.info(f'Recovered X: {x}, Recovered Y: {y}, sigma: {sigma}, Stride: {stride}')
        LOG.info(f'Recovered X: {x.shape}, Recovered Y: {y.shape}, sigma: {sigma.shape}, Stride: {stride}, v = {v.shape}')


        # Occupancy covers 2sigma.
        # Restrict this accumulation to 1sigma so that seeds for the same joint
        # are properly suppressed.

        # creates a high resolution map that is at the resolution of the input image. 
        # head output is in the coordinates of the CIF head that has an effective stride  with respect to the image

        scalar_square_add_gauss_with_max(
            t, x, y, sigma, v / self.neighbors / len_cifs, truncate=1.0)

    def fill(self, all_fields, metas):
        start = time.perf_counter()

        if self.accumulated is None:
            field_shape = all_fields[metas[0].head_index].shape
            shape = (
                field_shape[0],
                int((field_shape[2] - 1) * metas[0].stride + 1),
                int((field_shape[3] - 1) * metas[0].stride + 1),
            )
            ta = np.zeros(shape, dtype=np.float32)
        else:
            ta = np.zeros(self.accumulated.shape, dtype=np.float32)

        if not self.ablation_skip:
            for meta in metas:
                for t, p in zip(ta, all_fields[meta.head_index]):
                    self.accumulate(len(metas), t, p, meta.stride, meta.decoder_min_scale)

        if self.accumulated is None:
            self.accumulated = ta
        else:
            self.accumulated = np.maximum(ta, self.accumulated)

        LOG.info('target_intensities %.3fs', time.perf_counter() - start)
        self.debug_visualizer.predicted(self.accumulated)
        return self


class CifDetHr(CifHr):
    def accumulate(self, len_cifs, t, p, stride, min_scale):
        LOG.info(f'Original P: {p.shape}')
        p = p[:, p[0] > self.v_threshold]
        if min_scale:
            p = p[:, p[4] > min_scale / stride]
            p = p[:, p[5] > min_scale / stride]

        LOG.info(f'Updated p: {p.shape}')

        v, x, y, w, h, _, __ = p
        x = x * stride
        y = y * stride
        sigma = np.maximum(1.0, 0.1 * np.minimum(w, h) * stride)

        # LOG.info(f'Recovered X: {x}, Recovered Y: {y}, sigma: {sigma}, Stride: {stride}')
        LOG.info(f'Recovered X: {x.shape}, Recovered Y: {y.shape}, sigma: {sigma.shape}, Stride: {stride}')

        # Occupancy covers 2sigma.
        # Restrict this accumulation to 1sigma so that seeds for the same joint
        # are properly suppressed.
        scalar_square_add_gauss_with_max(
            t, x, y, sigma, v / self.neighbors / len_cifs, truncate=1.0)
