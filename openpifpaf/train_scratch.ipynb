{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import openpifpaf\n",
    "\n",
    "openpifpaf.show.Canvas.show = True\n",
    "openpifpaf.show.Canvas.image_min_dpi = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenPifPaf version 0.12.13+0.g6981019.dirty\n",
      "PyTorch version 1.10.0+cu102\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from openpifpaf import datasets, encoder, logger, network, optimize, plugin, show, visualizer,train\n",
    "\n",
    "from openpifpaf.network import trainer\n",
    "\n",
    "print('OpenPifPaf version', openpifpaf.__version__)\n",
    "print('PyTorch version', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:openpifpaf.train:neural network device: cuda (CUDA available: True, count: 1)\n",
      "INFO:openpifpaf.encoder.factory:Config Factory\n",
      "INFO:openpifpaf.network.basenetworks:resnet50: stride = 16, output features = 2048\n",
      "INFO:openpifpaf.network.heads:cif config: fields = 17, confidences = 1, vectors = 1, scales = 1 kernel = 1, padding = 0, dilation = 1\n",
      "INFO:openpifpaf.network.heads:Out Features: 85 , conv: Conv2d(2048, 85, kernel_size=(1, 1), stride=(1, 1)) \n",
      "INFO:openpifpaf.network.heads:caf config: fields = 19, confidences = 1, vectors = 2, scales = 2 kernel = 1, padding = 0, dilation = 1\n",
      "INFO:openpifpaf.network.heads:Out Features: 171 , conv: Conv2d(2048, 171, kernel_size=(1, 1), stride=(1, 1)) \n",
      "INFO:openpifpaf.network.losses.composite:cif: n_vectors = 1, n_scales = 1\n",
      "INFO:openpifpaf.network.losses.composite:caf: n_vectors = 2, n_scales = 2\n",
      "INFO:openpifpaf.network.losses.multi_head:multihead loss: ['cocokp.cif.c', 'cocokp.cif.vec1', 'cocokp.cif.scales1', 'cocokp.caf.c', 'cocokp.caf.vec1', 'cocokp.caf.vec2', 'cocokp.caf.scales1', 'cocokp.caf.scales2'], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "INFO:openpifpaf.plugins.coco.cocokp:Preprocess Encoder Data\n",
      "loading annotations into memory...\n",
      "Done (t=4.98s)\n",
      "creating index...\n",
      "index created!\n",
      "INFO:openpifpaf.plugins.coco.dataset:filter for annotations (min kp=1) ...\n",
      "INFO:openpifpaf.plugins.coco.dataset:... done.\n",
      "INFO:openpifpaf.plugins.coco.dataset:Images: 56599\n",
      "INFO:openpifpaf.plugins.coco.cocokp:Preprocess Encoder Data\n",
      "loading annotations into memory...\n",
      "Done (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "INFO:openpifpaf.plugins.coco.dataset:filter for annotations (min kp=1) ...\n",
      "INFO:openpifpaf.plugins.coco.dataset:... done.\n",
      "INFO:openpifpaf.plugins.coco.dataset:Images: 2346\n",
      "INFO:openpifpaf.optimize:SGD optimizer\n",
      "INFO:openpifpaf.optimize:training batches per epoch = 56599\n",
      "INFO:openpifpaf.network.trainer:{'type': 'config', 'field_names': ['cocokp.cif.c', 'cocokp.cif.vec1', 'cocokp.cif.scales1', 'cocokp.caf.c', 'cocokp.caf.vec1', 'cocokp.caf.vec2', 'cocokp.caf.scales1', 'cocokp.caf.scales2']}\n"
     ]
    }
   ],
   "source": [
    "args = train.cli()\n",
    "\n",
    "datamodule = datasets.factory(args.dataset)\n",
    "\n",
    "net_cpu, start_epoch = network.Factory().factory(head_metas=datamodule.head_metas)\n",
    "loss = network.losses.Factory().factory(net_cpu.head_nets)\n",
    "\n",
    "checkpoint_shell = None\n",
    "if not args.disable_cuda and torch.cuda.device_count() > 1 and not args.ddp:\n",
    "    checkpoint_shell = copy.deepcopy(net_cpu)\n",
    "    net = torch.nn.DataParallel(net_cpu.to(device=args.device))\n",
    "    loss = loss.to(device=args.device)\n",
    "elif not args.disable_cuda and torch.cuda.device_count() == 1 and not args.ddp:\n",
    "    checkpoint_shell = copy.deepcopy(net_cpu)\n",
    "    net = net_cpu.to(device=args.device)\n",
    "    loss = loss.to(device=args.device)\n",
    "elif not args.disable_cuda and torch.cuda.device_count() > 0:\n",
    "    assert not list(loss.parameters())\n",
    "    assert torch.cuda.device_count() > 0\n",
    "    checkpoint_shell = copy.deepcopy(net_cpu)\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
    "    if args.sync_batchnorm:\n",
    "        net_cpu = torch.nn.SyncBatchNorm.convert_sync_batchnorm(net_cpu)\n",
    "    else:\n",
    "        net = torch.nn.parallel.DistributedDataParallel(\n",
    "            net_cpu.to(device=args.device),\n",
    "            device_ids=[args.local_rank], output_device=args.local_rank,\n",
    "            find_unused_parameters=isinstance(datamodule, datasets.MultiDataModule),\n",
    "    )\n",
    "    loss = loss.to(device=args.device)\n",
    "else:\n",
    "    net = net_cpu\n",
    "\n",
    "# logger.train_configure(args)\n",
    "train_loader = datamodule.train_loader()\n",
    "val_loader = datamodule.val_loader()\n",
    "if torch.distributed.is_initialized():\n",
    "    train_loader = datamodule.distributed_sampler(train_loader)\n",
    "    val_loader = datamodule.distributed_sampler(val_loader)\n",
    "\n",
    "optimizer = optimize.factory_optimizer(\n",
    "    args, list(net.parameters()) + list(loss.parameters()))\n",
    "lr_scheduler = optimize.factory_lrscheduler(\n",
    "    args, optimizer, len(train_loader), last_epoch=start_epoch)\n",
    "trainer = network.Trainer(\n",
    "    net, loss, optimizer, args.output,\n",
    "    checkpoint_shell=checkpoint_shell,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    device=args.device,\n",
    "    model_meta_data={\n",
    "        'args': vars(args),\n",
    "        'plugin_versions': plugin.versions()\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:openpifpaf.encoder.cif:Confidence Shape: torch.Size([17, 25, 25])\n",
      "INFO:openpifpaf.encoder.cif:Confidence Fields: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "torch.Size([1, 3, 385, 385])\n",
      "INFO:openpifpaf.encoder.cif:Confidence Shape: torch.Size([17, 25, 25])\n",
      "INFO:openpifpaf.encoder.cif:Confidence Fields: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "INFO:openpifpaf.encoder.cif:Confidence Shape: torch.Size([17, 25, 25])\n",
      "INFO:openpifpaf.encoder.cif:Confidence Fields: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "INFO:openpifpaf.network.trainer:applying ema\n"
     ]
    }
   ],
   "source": [
    "# trainer.loop(train_loader, val_loader, start_epoch=start_epoch)\n",
    "\n",
    "# trainer.train(train_loader, start_epoch)\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.model.train()\n",
    "if trainer.fix_batch_norm is True \\\n",
    "    or (trainer.fix_batch_norm is not False and trainer.fix_batch_norm <= start_epoch):\n",
    "    for m in trainer.model.modules():\n",
    "        if isinstance(m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d)):\n",
    "            m.eval()\n",
    "\n",
    "trainer.ema_restore()\n",
    "trainer.ema = None\n",
    "\n",
    "epoch_loss = 0.0\n",
    "head_epoch_losses = None\n",
    "head_epoch_counts = None\n",
    "last_batch_end = time.time()\n",
    "trainer.optimizer.zero_grad()\n",
    "\n",
    "for batch_idx, (data, target, _) in enumerate(train_loader):\n",
    "    print(data.shape)\n",
    "    preprocess_time = time.time() - last_batch_end\n",
    "\n",
    "    # Train the batches on the pif paf \n",
    "    batch_start = time.time()\n",
    "    apply_gradients = batch_idx % trainer.stride_apply == 0\n",
    "    loss, head_losses = trainer.train_batch(data, target, apply_gradients)\n",
    "\n",
    "    # update epoch accumulates\n",
    "    if loss is not None:\n",
    "        epoch_loss += loss\n",
    "    if head_epoch_losses is None:\n",
    "        head_epoch_losses = [0.0 for _ in head_losses]\n",
    "        head_epoch_counts = [0 for _ in head_losses]\n",
    "    for i, head_loss in enumerate(head_losses):\n",
    "        if head_loss is None:\n",
    "            continue\n",
    "        head_epoch_losses[i] += head_loss\n",
    "        head_epoch_counts[i] += 1\n",
    "\n",
    "    batch_time = time.time() - batch_start\n",
    "\n",
    "    if batch_idx % trainer.log_interval == 0:\n",
    "        batch_info = {\n",
    "            'type': 'train',\n",
    "            'epoch': start_epoch, 'batch': batch_idx, 'n_batches': len(train_loader),\n",
    "            'time': round(batch_time, 3),\n",
    "            'data_time': round(preprocess_time, 3),\n",
    "            'lr': round(trainer.lr(), 8),\n",
    "            'loss': round(loss, 3) if loss is not None else None,\n",
    "            'head_losses': [round(l, 3) if l is not None else None\n",
    "                            for l in head_losses],\n",
    "        }\n",
    "\n",
    "        if hasattr(trainer.loss, 'batch_meta'):\n",
    "            batch_info.update(trainer.loss.batch_meta())\n",
    "\n",
    "    # initialize ema\n",
    "    if trainer.ema is None and trainer.ema_decay:\n",
    "        trainer.ema = copy.deepcopy([p.data for p in trainer.model.parameters()])\n",
    "\n",
    "    # update learning rate\n",
    "    if trainer.lr_scheduler is not None:\n",
    "        trainer.lr_scheduler.step()\n",
    "\n",
    "    if trainer.n_train_batches and batch_idx + 1 >= trainer.n_train_batches:\n",
    "        break\n",
    "\n",
    "    last_batch_end = time.time()\n",
    "\n",
    "    break\n",
    "\n",
    "trainer.apply_ema()\n",
    "trainer.n_clipped_grad = 0\n",
    "trainer.max_norm = 0.0\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42f01ea88de992bfe030ae62812b3bd75e246cedf5d649171f226dc078740c9d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('pifpaf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
