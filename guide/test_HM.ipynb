{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import openpifpaf\n",
    "\n",
    "openpifpaf.show.Canvas.show = True\n",
    "openpifpaf.show.Canvas.image_min_dpi = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "print('OpenPifPaf version', openpifpaf.__version__)\n",
    "print('PyTorch version', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_im = PIL.Image.open(r\"/home/hestia/Documents/Experiments/Test/openpifpaf/openpifpaf/old/sample.jpg\").convert('RGB')\n",
    "im = np.asarray(pil_im)\n",
    "\n",
    "print(im.shape)\n",
    "\n",
    "with openpifpaf.show.image_canvas(im) as ax:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openpifpaf.plugins.coco.CocoKp().head_metas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = openpifpaf.Predictor(checkpoint='resnet50')\n",
    "predictions, gt_anns, image_meta = predictor.pil_image(pil_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gt_anns)\n",
    "# print(image_meta)\n",
    "for i in range (len(predictions)):\n",
    "    print(predictions[i].data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the predicted annotations in `predictions`\n",
    "\n",
    "annotation_painter = openpifpaf.show.AnnotationPainter()\n",
    "with openpifpaf.show.image_canvas(im) as ax:\n",
    "    annotation_painter.annotations(ax, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THe prediction in the `predictions` list is a type of `Annotation` it can access the joint coordinates in the `data` attribute. \n",
    "# Numpy array that contains the x and y coors and the confidence for every joint:\n",
    "\n",
    "predictions[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Predictor` class can also be created with `json_data=True` and then it will\n",
    "return JSON serializable dicts and list instead of `Annotation` objects.\n",
    "\n",
    "The other items that are returned are ground truth annotations (`gt_anns`) which\n",
    "are not provided for this image and meta information about the image (`image_meta`)\n",
    "which is useful to understand the transformations that were applied before\n",
    "passing the image through the neural network. Usually, you don't need `image_meta`\n",
    "as the inverse transform has already been applied to ground truth and predictions\n",
    "in the `Predictor` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openpifpaf.visualizer.Base.set_all_indices(['cif,caf:5:confidence'])\n",
    "_ = predictor.pil_image(pil_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openpifpaf.visualizer.Base.set_all_indices(['cif,caf:5:regression'])\n",
    "_ = predictor.pil_image(pil_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the CIF field, a high resolution accumulation (in the code it's called `CifHr`) is generated.\n",
    "This is also the basis for the seeds. Both are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openpifpaf.visualizer.Base.set_all_indices(['cif:5:hr', 'seeds'])\n",
    "_ = predictor.pil_image(pil_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from a seed, the poses are constructed. At every joint position, an occupancy map marks whether a previous pose was already constructed here. This reduces the number of poses that are constructed from multiple seeds for the same person. The final occupancy map is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openpifpaf.visualizer.Base.set_all_indices(['occupancy:5'])\n",
    "_ = predictor.pil_image(pil_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openpifpaf.decoder.utils.cif_hr.debug_visualizer = openpifpaf.visualizer.CifHr()\n",
    "openpifpaf.visualizer.CifHr.show = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_cpu, _ = openpifpaf.network.Factory(checkpoint='resnet50').factory()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "net = net_cpu.to(device)\n",
    "\n",
    "\n",
    "openpifpaf.decoder.utils.CifSeeds.threshold = 0.5\n",
    "openpifpaf.decoder.utils.nms.Keypoints.keypoint_threshold = 0.2\n",
    "openpifpaf.decoder.utils.nms.Keypoints.instance_threshold = 0.2\n",
    "processor = openpifpaf.decoder.factory([hn.meta for hn in net.head_nets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = openpifpaf.datasets.PilImageList([pil_im])\n",
    "loader = torch.utils.data.DataLoader(\n",
    "  data, batch_size=1, pin_memory=True, \n",
    "  collate_fn=openpifpaf.datasets.collate_images_anns_meta)\n",
    "\n",
    "# openpifpaf.show.Canvas.show = True\n",
    "# annotation_painter = openpifpaf.show.AnnotationPainter()\n",
    "\n",
    "for images_batch, _, __ in loader:\n",
    "  predictions = processor.batch(net, images_batch, device=device)[0]\n",
    "  # with openpifpaf.show.image_canvas(im) as ax:\n",
    "  #   annotation_painter.annotations(ax, predictions)\n",
    "print(predictions[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openpifpaf.plugins.coco.CocoKp().head_metas[0]\n",
    "# image_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the fields\n",
    "field = processor.fields_batch(net, images_batch, device=device)[0]\n",
    "\n",
    "# Create cif instance \n",
    "cif = openpifpaf.visualizer.Cif(openpifpaf.plugins.coco.CocoKp().head_metas[0])\n",
    "cif.predicted(field[0])\n",
    "\n",
    "#field [0] is pif while field [1] is paf\n",
    "print(field[0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(field[0][:, 0].shape)\n",
    "# print(field[0])\n",
    "\n",
    "# Example give indexes to cif for a specific joint type (0 - 16)\n",
    "# debug_indices = ['cif:5']\n",
    "# print(debug_indices)\n",
    "# debug_indices = [di.partition(':') for di in debug_indices]\n",
    "# debug_indices = [(di[0], int(di[2])) for di in debug_indices]\n",
    "# cif.all_indices = debug_indices\n",
    "\n",
    "# Create the confidence heatmap\n",
    "confidences = field[0][:, 0]\n",
    "\n",
    "print(confidences.shape)\n",
    "\n",
    "img = plt.imread('/home/hestia/Documents/Experiments/Test/openpifpaf/openpifpaf/old/sample.jpg')\n",
    "\n",
    "for f in range (16):\n",
    "    imgplot = plt.imshow(img)\n",
    "    hm = cif.scale_scalar(confidences[f], 8)\n",
    "    print(hm.shape)\n",
    "    plt.imshow(hm , alpha=0.9, vmin=0.0, vmax=1.0, cmap='Oranges')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy config arg\n",
    "config = openpifpaf.decoder.FieldConfig()\n",
    "\n",
    "for images_batch, _, __ in loader:\n",
    "    images_batch = images_batch.cuda()\n",
    "\n",
    "    # Get the field\n",
    "    field = processor.fields_batch(net, images_batch, device=device)[0]\n",
    "\n",
    "    # Accumulate the field and extract the heatmap\n",
    "    cif = openpifpaf.decoder.CifHr(config)\n",
    "    cif.fill(field)\n",
    "    heatmap = cif.accumulated.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the field, I'm not sure what it is, but cif.py is using it\n",
    "field = processor.fields_batch(net, images_batch, device=device)[0]\n",
    "\n",
    "# Create cif instance \n",
    "cif = openpifpaf.visualizer.Cif(openpifpaf.plugins.coco.CocoKp().head_metas[0])\n",
    "cif.predicted(field[0])\n",
    "\n",
    "# Create the heatmap\n",
    "confidences = field[0][:, 0]\n",
    "\n",
    "img = plt.imread('/home/hestia/Documents/Experiments/Test/openpifpaf/openpifpaf/old/sample.jpg')\n",
    "\n",
    "cif_hr = openpifpaf.decoder.utils.CifHr()\n",
    "cif_hr.fill(field,cif)\n",
    "hr_heatmap = cif_hr.accumulate()\n",
    "\n",
    "print(hr_heatmap.shape)\n",
    "\n",
    "# for f in range (16):\n",
    "#     imgplot = plt.imshow(img)\n",
    "#     hm = cif.scale_scalar(confidences[f], 8)\n",
    "#     print(hm.shape)\n",
    "#     plt.imshow(hm , alpha=0.9, vmin=0.0, vmax=1.0, cmap='Oranges')\n",
    "#     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea6946363a43e80d241452ab397f4c58bdd3d2517da174158e9c46ce6717422a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('venv3': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
